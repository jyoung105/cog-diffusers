#!/usr/bin/env python3

# #! SheBang #!<interpreter> [optional-arg]

"""
Run this script before deploying it on Replicate to pre-download model weights,
which avoids long download times during runtime.
"""

# Standard library imports
import os
import sys
import shutil

# Add current directory to sys.path
sys.path.append('.')

# Third-party imports
import torch
from diffusers import KolorsPipeline

# Local imports
from predict import (
    MODEL_ID, 
    MODEL_CACHE,
    REPO_CACHE,
    DTYPE,
)

# Set environment variables
# Enable hf_transfer for faster uploads and downloads from the Hub
# https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhubenablehftransfer
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"


def main():
    # Load pipeline
    pipe = KolorsPipeline.from_pretrained(
        REPO_CACHE,
        variant="fp16",
        torch_dtype=DTYPE,
        use_safetensors=True,
    )

    # TODO: Optimize the saved pipeline to include only necessary components (unet, tokenizer, config)
    pipe.save_pretrained(MODEL_CACHE, safe_serialization=True, variant="fp16")

    # Delete original model directory to decrease the size of the Docker image
    dir_to_delete = [REPO_CACHE]
    for dirname in dir_to_delete:
        shutil.rmtree(dirname)


if __name__ == "__main__":
    main()