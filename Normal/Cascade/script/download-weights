#!/usr/bin/env python

# Run this before you deploy it on replicate, because if you don't whenever you run the model, 
# it will download the weights from the internet, which will take a long time.

import os
import sys

import torch

from diffusers import StableCascadeDecoderPipeline, StableCascadePriorPipeline

sys.path.append('.') # append project directory to path so predict.py can be imported

from predict import PRIOR_CACHE, DECODER_CACHE, PRIOR_ID, DECODER_ID


# Set to True for faster uploads and downloads from the Hub using hf_transfer.
# https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhubenablehftransfer
os.environ["HF_HUB_ENABLE_HF_TRANSFER"]="1"


prior = StableCascadePriorPipeline.from_pretrained(
    PRIOR_ID, 
    variant="bf16", 
    torch_dtype=torch.bfloat16,
    use_safetensors=True,
)

decoder = StableCascadeDecoderPipeline.from_pretrained(
    DECODER_ID, 
    variant="bf16", 
    torch_dtype=torch.float16,
    use_safetensors=True,
)


# TODO - we don't need to save all of this and in fact should save just the unet, tokenizer, and config.
prior.save_pretrained(PRIOR_CACHE, safe_serialization=True, variant="bf16")
decoder.save_pretrained(DECODER_CACHE, safe_serialization=True, variant="bf16")