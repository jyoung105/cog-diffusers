#!/usr/bin/env python3

# #! SheBang #!<interpreter> [optional-arg]

"""
Run this script before deploying it on Replicate to pre-download model weights,
which avoids long download times during runtime.
"""

# Standard library imports
import os
import sys

# Add current directory to sys.path
sys.path.append('.')

# Third-party imports
import torch
from diffusers import (
    StableDiffusionXLPipeline, 
    AutoencoderKL, 
    UNet2DConditionModel, 
    LCMScheduler,
)
from huggingface_hub import hf_hub_download
from safetensors.torch import load_file

# Local imports
from predict import (
    TOTAL_CACHE,
    MODEL_ID,
    MODEL_CACHE,
    VAE_ID,
    DMD_ID, 
    DMD_FILE, 
    DEVICE, 
    DTYPE,
)

# Set environment variables
# Enable hf_transfer for faster uploads and downloads from the Hub
# https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhubenablehftransfer
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"


def main():
    # Download model and VAE
    hf_hub_download(VAE_ID, "sdxl.vae.safetensors", local_dir=TOTAL_CACHE)
    hf_hub_download(MODEL_ID, "sd_xl_base_1.0.safetensors", local_dir=TOTAL_CACHE)
    hf_hub_download(MODEL_ID, "unet/config.json", local_dir=TOTAL_CACHE)
    hf_hub_download(DMD_ID, DMD_FILE, local_dir=TOTAL_CACHE)
    
    # Load U-Net
    unet = UNet2DConditionModel.from_config(
        TOTAL_CACHE, 
        subfolder="unet",
    ).to(DEVICE, DTYPE)
    unet.load_state_dict(load_file(f"{TOTAL_CACHE}/{DMD_FILE}", device=DEVICE))
    
    # Load VAE
    vae = AutoencoderKL.from_single_file(
        os.path.join(TOTAL_CACHE, "sdxl.vae.safetensors"),
        torch_dtype=DTYPE,
    )
    
    # Load pipeline
    pipe = StableDiffusionXLPipeline.from_single_file(
        os.path.join(TOTAL_CACHE, "sd_xl_base_1.0.safetensors"),
        unet=unet,
        vae=vae,
        torch_dtype=DTYPE,
        use_safetensors=True,
    )
    
    # Set scheduler
    pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
    
    # TODO: Optimize the saved pipeline to include only necessary components (unet, tokenizer, config)
    pipe.save_pretrained(MODEL_CACHE, safe_serialization=True, variant="fp16")
    
    # Download embeddings
    hf_hub_download("jyoung105/general-neg", "ac_neg1.safetensors", local_dir=TOTAL_CACHE)
    hf_hub_download("jyoung105/general-neg", "ac_neg2.safetensors", local_dir=TOTAL_CACHE)
    
    # Delete original model files to decrease the size of the Docker image
    files_to_delete = ["sdxl.vae.safetensors", "sd_xl_base_1.0.safetensors"]
    for filename in files_to_delete:
        filepath = os.path.join(TOTAL_CACHE, filename)
        if os.path.isfile(filepath):
            os.remove(filepath)


if __name__ == "__main__":
    main()